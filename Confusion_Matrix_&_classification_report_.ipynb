{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Confusion Matrix & classification report\n",
        "\n",
        "A confusion matrix is a performance evaluation tool for classification problems. It shows how many predictions were correct and incorrect, organized by actual vs. predicted classes.\n",
        "\n",
        "--------------------------------------------------------------\n",
        "üîπ Basic Structure (for Binary Classification):\n",
        "--------------------------------------------------------------\n",
        "|                      | **Predicted: Positive**   | **Predicted: Negative**   |\n",
        "| -------------------- | ------------------------- | ------------------------- |\n",
        "| **Actual: Positive** | ‚úÖ **True Positive (TP)**  | ‚ùå **False Negative (FN)** |\n",
        "| **Actual: Negative** | ‚ùå **False Positive (FP)** | ‚úÖ **True Negative (TN)**  |\n",
        "\n",
        "---------------------------------------------------------------\n",
        "#üî∏ Explanation of Terms:\n",
        "---------------------------------------------------------------\n",
        "\n",
        "True Positive (TP): Model correctly predicted Positive class\n",
        "\n",
        "True Negative (TN): Model correctly predicted Negative class\n",
        "\n",
        "False Positive (FP): Model incorrectly predicted Positive (a \"Type I\" error)\n",
        "\n",
        "False Negative (FN): Model incorrectly predicted Negative (a \"Type II\" error)\n",
        "\n",
        "\n",
        "#üîπ Example:\n",
        "\n",
        "\n",
        "Suppose we have a binary classifier that predicts whether emails are spam.\n",
        "\n",
        "|                       | Spam (Predicted) | Not Spam (Predicted) |\n",
        "| --------------------- | ---------------- | -------------------- |\n",
        "| **Spam (Actual)**     | 90 (TP)          | 10 (FN)              |\n",
        "| **Not Spam (Actual)** | 15 (FP)          | 85 (TN)              |\n",
        "\n",
        "\n",
        "\n",
        "üìà From Confusion Matrix, You Can Calculate: classification Report\n",
        "\n",
        "\n",
        "\n",
        "| Metric                   | Formula                                                        |\n",
        "| ------------------------ | -----------------------------------------------------------    |\n",
        "| **Accuracy**             | $(TP + TN) / (TP + TN + FP + FN)$                           |\n",
        "| **Precision**            | $TP / (TP + FP)$                                            |\n",
        "| **Recall (Sensitivity)** | $TP / (TP + FN)$                                            |\n",
        "| **F1 Score**             | $2 \\cdot \\frac{Precision \\cdot Recall}{Precision + Recall}$ |\n",
        "| **Specificity**          | $TN / (TN + FP)$                                            |\n",
        "\n"
      ],
      "metadata": {
        "id": "C3Hy4hT1Z2VA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKs0E4CyZqZn",
        "outputId": "17eb146d-9480-481f-bb79-4345b6662d36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            " [[3 1]\n",
            " [1 3]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "y_true = [1, 0, 1, 1, 0, 1, 0, 0]   # Actual labels\n",
        "y_pred = [1, 0, 1, 0, 0, 1, 1, 0]   # Predicted labels\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary:\n",
        "\n",
        "Confusion matrix is key for understanding classification model performance\n",
        "\n",
        "Helps to detect imbalanced accuracy, where accuracy alone is misleading\n",
        "\n",
        "Useful in binary and multi-class classification"
      ],
      "metadata": {
        "id": "uT_PK5Xjaft-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ClZiECsOahSW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}